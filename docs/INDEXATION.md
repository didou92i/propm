# üìö Guide d'Indexation Vectorielle - Plateforme Azzabi

## üéØ Vue d'ensemble

Ce document d√©crit l'architecture compl√®te du syst√®me d'indexation vectorielle optimis√© de la plateforme Azzabi. Le syst√®me utilise **pgvector** avec des index **HNSW** (Hierarchical Navigable Small World) pour des recherches s√©mantiques ultra-rapides.

### Technologies Cl√©s
- **Supabase pgvector** : Extension PostgreSQL pour les vecteurs
- **Index HNSW** : Approximative Nearest Neighbor (ANN) optimis√©
- **OpenAI Embeddings** : `text-embedding-3-small` (1536 dimensions)
- **LlamaIndex** : Framework d'orchestration documentaire
- **SupabaseVectorStore** : Service d'int√©gration personnalis√©

---

## üèóÔ∏è Architecture du Syst√®me

### 1. Index Primaire - Documents (HNSW)

```sql
CREATE INDEX documents_embedding_hnsw_idx 
ON public.documents 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 24, ef_construction = 128);
```

**Param√®tres optimis√©s :**
- `m = 24` : Nombre de connexions bidirectionnelles par n≈ìud (√©quilibre m√©moire/pr√©cision)
- `ef_construction = 128` : Qualit√© de l'index lors de la construction (temps vs pr√©cision)

**Cas d'usage :** Recherche dans les documents upload√©s (PDF, Word, images, texte)

### 2. Index Secondaire - Job Posts (IVFFlat)

```sql
CREATE INDEX job_posts_embedding_ivfflat_idx 
ON public.job_posts 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 200);
```

**Param√®tres :**
- `lists = 200` : Nombre de clusters pour la partition des donn√©es

**Cas d'usage :** Recherche d'offres d'emploi par similarit√© s√©mantique

### 3. Index Composite de Performance

```sql
CREATE INDEX idx_documents_user_embedding 
ON public.documents (user_id, embedding);
```

**Objectif :** Acc√©l√©ration des requ√™tes filtr√©es par utilisateur avec RLS (Row Level Security)

---

## üì• Flux d'Upload de Documents

### √âtape 1 : Upload Client
```typescript
// src/components/document/DocumentUpload.tsx
const formData = new FormData();
formData.append('file', file);

const { data, error } = await supabase.functions.invoke('process-document', {
  body: formData
});
```

### √âtape 2 : Traitement Edge Function
**Fichier :** `supabase/functions/process-document/index.ts`

1. **Extraction de texte**
   - PDF : GPT-4.1 via OpenAI API
   - Word : GPT-4.1 extraction structur√©e
   - Images : OCR via GPT-4.1 Vision
   - Texte : Lecture directe

2. **Chunking intelligent**
   ```typescript
   const chunks = chunkText(extractedText, 1000); // 1000 caract√®res/chunk
   ```

3. **G√©n√©ration d'embeddings**
   ```typescript
   const embedding = await fetch('https://api.openai.com/v1/embeddings', {
     method: 'POST',
     body: JSON.stringify({
       model: 'text-embedding-3-small',
       input: chunk
     })
   });
   ```

4. **Indexation via SupabaseVectorStore**
   ```typescript
   const vectorStore = new SupabaseVectorStoreService(supabase, openAIApiKey);
   
   const documentIds = await vectorStore.addDocuments(
     chunks.map((chunk, index) => ({
       text: chunk,
       metadata: {
         filename: file.name,
         chunk_index: index,
         total_chunks: chunks.length,
         indexed_by: 'llamaindex'
       }
     }))
   );
   ```

### √âtape 3 : Stockage Optimis√©
- **Insertion directe** dans `public.documents`
- **Index HNSW** appliqu√© automatiquement
- **Metadata enrichie** pour filtrage avanc√©

**Temps de traitement typique :**
- Document texte (10 pages) : ~2-5 secondes
- PDF avec OCR (20 pages) : ~10-15 secondes
- Image avec OCR : ~3-5 secondes

---

## üîç Flux de Recherche S√©mantique

### Architecture de Recherche

```mermaid
graph LR
    A[User Query] --> B[Generate Embedding]
    B --> C{Search Strategy}
    C -->|Standard| D[match_documents RPC]
    C -->|Hierarchical| E[match_documents_hierarchical RPC]
    D --> F[HNSW Index Scan]
    E --> F
    F --> G[Results + Similarity Scores]
    G --> H[Client Display]
```

### 1. Recherche Standard

**Hook :** `src/hooks/useSemanticSearch.ts`

```typescript
const semanticSearch = async (query: string, options?: SearchOptions) => {
  const searchStart = performance.now();
  
  // 1. G√©n√©rer embedding de la requ√™te
  const queryEmbedding = await generateEmbedding(query);
  
  // 2. Recherche via RPC optimis√©e HNSW
  const { data: results } = await supabase.rpc('match_documents', {
    query_embedding: `[${queryEmbedding.join(',')}]`,
    match_count: 10
  });
  
  const searchTime = performance.now() - searchStart;
  console.log(`‚úÖ Search completed in ${searchTime.toFixed(0)}ms using HNSW`);
  
  return results;
};
```

**RPC Function :**
```sql
CREATE OR REPLACE FUNCTION match_documents(
  query_embedding vector(1536),
  match_count integer DEFAULT 5,
  filter jsonb DEFAULT '{}'::jsonb
)
RETURNS TABLE (
  id uuid,
  content text,
  metadata jsonb,
  similarity double precision
)
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
SET enable_seqscan = off  -- Force l'utilisation de l'index HNSW
AS $$
BEGIN
  RETURN QUERY
  SELECT
    d.id,
    d.content,
    d.metadata,
    1 - (d.embedding <=> query_embedding) as similarity
  FROM public.documents d
  WHERE d.user_id = auth.uid()
    AND d.embedding IS NOT NULL
  ORDER BY d.embedding <=> query_embedding
  LIMIT match_count;
END;
$$;
```

**Param√®tre critique :** `SET enable_seqscan = off` force PostgreSQL √† utiliser l'index HNSW au lieu d'un scan s√©quentiel.

### 2. Recherche Hi√©rarchique

**Hook :** `src/hooks/useHierarchicalSearch.ts`

Recherche multi-niveaux avec fusion de scores :
- **Niveau Titre** : Poids 0.4
- **Niveau Paragraphe** : Poids 0.4
- **Niveau Document** : Poids 0.2

```typescript
const hierarchicalSearch = async (query: string) => {
  const queryEmbedding = await getCachedEmbedding(query);
  
  // Recherche parall√®le √† tous les niveaux
  const [titleResults, paragraphResults, documentResults] = await Promise.all([
    searchAtLevel(queryEmbedding, 'title', 20),
    searchAtLevel(queryEmbedding, 'paragraph', 20),
    searchAtLevel(queryEmbedding, 'document', 20)
  ]);
  
  // Fusion des scores
  return fuseSearchResults(titleResults, paragraphResults, documentResults, weights);
};
```

**RPC Hi√©rarchique :**
```sql
CREATE OR REPLACE FUNCTION match_documents_hierarchical(
  query_embedding vector(1536),
  match_count integer DEFAULT 10,
  level_filter text DEFAULT NULL
)
-- ... impl√©mentation similaire avec filtrage par metadata->>'level'
```

### 3. Recherche Contextuelle (LlamaIndex)

**Service :** `src/services/llama/searchEngine.ts`

```typescript
async contextualSearch(
  query: string, 
  conversationHistory: string[], 
  maxResults: number = 5
) {
  // Cr√©er contexte enrichi avec historique
  const contextualQuery = this.buildContextualQuery(query, conversationHistory);
  
  const response = await this.queryEngine.query({
    query: contextualQuery,
    similarityTopK: maxResults * 2
  });
  
  return response.sourceNodes.map(node => ({
    content: node.node.getText(),
    score: node.score,
    relevanceScore: this.calculateRelevanceScore(node, query)
  }));
}
```

---

## ‚ö° Performances Attendues

### Benchmarks Typiques

| Op√©ration | Temps (HNSW) | Temps (Sans Index) | Gain |
|-----------|--------------|-------------------|------|
| Recherche 5 docs | ~50-100ms | ~800-1500ms | **10-15x** |
| Recherche 50 docs | ~80-150ms | ~2000-4000ms | **20-25x** |
| Upload + Index 1 doc | ~2-5s | N/A | - |
| Upload + Index 10 docs | ~8-15s | N/A | - |

### Facteurs d'Optimisation

**‚úÖ Bonnes pratiques :**
- Activer `enable_seqscan = off` dans les RPC
- Utiliser des chunks de ~1000 caract√®res
- Mettre en cache les embeddings de requ√™tes fr√©quentes
- Filtrer par `user_id` pour exploiter l'index composite

**‚ùå Anti-patterns :**
- Recherches sans filtres (scan complet)
- Chunks trop petits (<200 chars) ou trop grands (>2000 chars)
- G√©n√©ration d'embeddings c√¥t√© client
- Requ√™tes SQL directes sans RPC (bypass l'index)

---

## üõ†Ô∏è Maintenance et Optimisation

### 1. Monitoring de Performance

**Fonction RPC :** `get_index_performance()`

```sql
SELECT * FROM get_index_performance();
```

**Retourne :**
```json
{
  "documents_index": {
    "index_name": "documents_embedding_hnsw_idx",
    "scans": 1523,
    "tuples_read": 15230,
    "tuples_fetched": 7615,
    "index_size": "256 MB",
    "table_size": "1.2 GB"
  },
  "recommendations": [
    "Index fonctionnel et utilis√© r√©guli√®rement"
  ]
}
```

**Composant UI :** `src/components/monitoring/IndexPerformancePanel.tsx`

### 2. R√©indexation

**Quand r√©indexer ?**
- Apr√®s >10,000 nouvelles insertions
- Si `index_size / table_size` > 30%
- Apr√®s changement des param√®tres HNSW

**Commande :**
```sql
REINDEX INDEX documents_embedding_hnsw_idx;
```

**Downtime :** ~5-30 minutes selon la taille (mode CONCURRENTLY recommand√© en production)

### 3. Nettoyage de Cache

**Service :** `src/services/hierarchicalEmbeddings.ts`

```typescript
// Nettoyer le cache d'embeddings (1h de TTL par d√©faut)
hierarchicalEmbeddingService.clearCache();

// Obtenir les stats
const stats = hierarchicalEmbeddingService.getCacheStats();
// { size: 250, maxSize: 1000, hitRate: 0.68 }
```

### 4. Optimisation PostgreSQL

**Configuration recommand√©e** (`postgresql.conf`) :
```ini
shared_buffers = 2GB              # 25% de la RAM
effective_cache_size = 6GB        # 75% de la RAM
maintenance_work_mem = 512MB      # Pour REINDEX
random_page_cost = 1.1            # SSD
effective_io_concurrency = 200    # SSD
```

---

## üß™ Tests et Validation

### Composant de Test Automatis√©

**Fichier :** `src/components/diagnostics/IndexValidation.tsx`

**Page d'acc√®s :** `/diagnostics` ‚Üí Onglet "Validation Index Vectoriels"

### Tests Effectu√©s

1. **Test de Recherche S√©mantique**
   - Requ√™te : `"arr√™t√© municipal police"`
   - Mesure du temps de r√©ponse
   - V√©rification du nombre de r√©sultats
   - **Crit√®res :**
     - ‚úÖ Excellent : <100ms
     - ‚ö†Ô∏è Acceptable : 100-500ms
     - ‚ùå Lent : >500ms

2. **Test d'Utilisation de l'Index**
   - V√©rifie que `documents_embedding_hnsw_idx` est utilis√©
   - Compte les scans et tuples lus
   - **Crit√®res :**
     - ‚úÖ Active : scans > 0
     - ‚ùå Inactive : scans = 0 (probl√®me de configuration)

3. **Test de Couverture des Documents**
   - Calcule % de documents index√©s avec LlamaIndex
   - V√©rifie la coh√©rence des m√©tadonn√©es
   - **Crit√®res :**
     - ‚úÖ Optimal : >80%
     - ‚ö†Ô∏è Acceptable : 50-80%
     - ‚ùå Probl√®me : <50%

4. **Recommandations Automatiques**
   - Analyse des r√©sultats
   - G√©n√©ration de suggestions d'optimisation
   - D√©tection des anomalies

### Tests Manuels

**Test de recherche en console :**
```typescript
// Dans la console navigateur
const { supabaseVectorStore } = await import('/src/services/llama/supabaseVectorStore.ts');
const results = await supabaseVectorStore.query('test query', 5);
console.log('Results:', results);
```

**V√©rification SQL directe :**
```sql
-- V√©rifier l'existence de l'index
SELECT indexname, indexdef 
FROM pg_indexes 
WHERE tablename = 'documents' 
  AND indexname LIKE '%hnsw%';

-- Tester une recherche manuelle
SELECT id, content, metadata, 
       1 - (embedding <=> '[0.1, 0.2, ...]'::vector) as similarity
FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector
LIMIT 5;
```

---

## üö® Troubleshooting

### Probl√®me 1 : Index HNSW non utilis√©

**Sympt√¥mes :**
- Recherches lentes (>1s)
- `get_index_performance()` montre 0 scans
- Logs indiquent "Sequential Scan"

**Solutions :**
1. V√©rifier que `enable_seqscan = off` dans la RPC function
2. Ex√©cuter `ANALYZE documents;` pour mettre √† jour les statistiques
3. V√©rifier que les embeddings ne sont pas NULL
4. Augmenter `effective_cache_size` dans PostgreSQL

**Commande de diagnostic :**
```sql
EXPLAIN ANALYZE
SELECT * FROM documents
ORDER BY embedding <=> '[...]'::vector
LIMIT 10;

-- Doit montrer "Index Scan using documents_embedding_hnsw_idx"
```

### Probl√®me 2 : Documents non trouv√©s

**Sympt√¥mes :**
- `semanticSearch()` retourne []
- Documents visibles en base mais absents des r√©sultats

**Solutions :**
1. V√©rifier `metadata->>'indexed_by' = 'llamaindex'`
2. V√©rifier que `user_id` correspond √† l'utilisateur authentifi√© (RLS)
3. V√©rifier que `embedding IS NOT NULL`
4. Tester avec `threshold = 0` pour voir tous les r√©sultats

**Requ√™te de diagnostic :**
```sql
SELECT 
  COUNT(*) as total,
  COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as with_embedding,
  COUNT(CASE WHEN metadata->>'indexed_by' = 'llamaindex' THEN 1 END) as indexed_llama
FROM documents
WHERE user_id = auth.uid();
```

### Probl√®me 3 : Temps de recherche lents

**Solutions progressives :**

1. **Court terme (minutes)** :
   ```sql
   ANALYZE documents;  -- Mise √† jour des stats
   ```

2. **Moyen terme (heures)** :
   ```sql
   -- Augmenter ef_construction
   DROP INDEX documents_embedding_hnsw_idx;
   CREATE INDEX documents_embedding_hnsw_idx 
   ON documents USING hnsw (embedding vector_cosine_ops)
   WITH (m = 32, ef_construction = 256);
   ```

3. **Long terme (jours)** :
   - Partitionner la table `documents` par date
   - Impl√©menter un cache Redis pour les requ√™tes fr√©quentes
   - Utiliser un CDN pour les embeddings statiques

### Probl√®me 4 : Upload √©choue

**Erreurs courantes :**

**"Embedding generation failed"** :
- V√©rifier `OPENAI_API_KEY` dans les secrets Supabase
- V√©rifier les quotas OpenAI
- Impl√©menter un retry avec backoff

**"Failed to store document"** :
- V√©rifier les permissions RLS sur `documents`
- V√©rifier que `user_id` est d√©fini
- V√©rifier la taille du document (<20MB)

**Logs √† consulter :**
```typescript
// Edge function logs (Supabase Dashboard)
// Rechercher "process-document"
```

---

## üìà √âvolution et Roadmap

### Am√©liorations Pr√©vues

**Phase 5 : Clustering Intelligent**
- K-means sur les embeddings pour cat√©gorisation auto
- D√©tection de documents similaires/doublons
- Suggestions de tags automatiques

**Phase 6 : Recherche Hybride**
- Combinaison full-text search + vectorielle
- Boosting par pertinence temporelle
- Filtres avanc√©s (date, type, auteur)

**Phase 7 : Multimodal**
- Embeddings d'images natives (CLIP)
- Recherche vid√©o par transcription
- Recherche audio

### Alternatives Technologiques

**Si HNSW ne suffit plus :**
- **Pinecone** : Service manag√© sp√©cialis√©
- **Qdrant** : Open-source performant
- **Weaviate** : Avec capacit√©s GraphQL
- **Milvus** : Pour tr√®s grandes √©chelles (>100M vecteurs)

---

## üîó Ressources et R√©f√©rences

### Documentation Officielle
- [Supabase Vector Guide](https://supabase.com/docs/guides/ai/vector-columns)
- [pgvector Extension](https://github.com/pgvector/pgvector)
- [HNSW Algorithm Paper](https://arxiv.org/abs/1603.09320)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

### Code Source Cl√©
- `src/services/llama/supabaseVectorStore.ts` - Service principal
- `supabase/functions/process-document/index.ts` - Upload et indexation
- `src/hooks/useSemanticSearch.ts` - Hook de recherche
- `src/components/diagnostics/IndexValidation.tsx` - Tests automatis√©s

### Support et Communaut√©
- Issues GitHub du projet
- Supabase Discord (#vector-search)
- √âquipe de d√©veloppement Azzabi

---

## üìù Changelog

### Version 1.2.0 (2025-01-10)
- ‚úÖ Migration vers HNSW avec param√®tres optimis√©s (m=24, ef=128)
- ‚úÖ Int√©gration SupabaseVectorStore dans process-document
- ‚úÖ Audit et optimisation des hooks de recherche
- ‚úÖ Ajout de logs de performance d√©taill√©s
- ‚úÖ Tests de validation automatis√©s
- ‚úÖ Documentation compl√®te

### Version 1.1.0 (Pr√©c√©dent)
- Index IVFFlat basique
- Recherche s√©mantique simple
- Upload de documents PDF/Word

### Version 1.0.0 (Initial)
- Stockage documentaire sans index vectoriel
- Recherche full-text PostgreSQL

---

## ‚úÖ Checklist de D√©ploiement

Avant de d√©ployer en production :

- [ ] Tests de validation passent √† 100%
- [ ] Index HNSW cr√©√© et utilis√© (v√©rifier `get_index_performance()`)
- [ ] RLS activ√© sur `documents` et `job_posts`
- [ ] Secrets configur√©s (`OPENAI_API_KEY`, `OPENAI_EMBEDDINGS_API_KEY`)
- [ ] Edge functions d√©ploy√©es et test√©es
- [ ] Monitoring configur√© (logs, alertes)
- [ ] Backup automatique activ√©
- [ ] Documentation √† jour pour l'√©quipe
- [ ] Plan de rollback d√©fini

---

**Derni√®re mise √† jour :** 2025-01-10  
**Mainteneurs :** √âquipe Azzabi Platform  
**Contact :** [Support technique]
