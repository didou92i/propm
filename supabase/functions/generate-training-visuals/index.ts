import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const openAIApiKey = Deno.env.get('OPENAI_API_KEY');

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  console.log('üéØ [VISUAL-GEN] D√©but de la g√©n√©ration visuelle');
  console.log('üîë [API-KEY] OpenAI API Key pr√©sente:', !!openAIApiKey);

  try {
    const requestBody = await req.json();
    console.log('üì• [REQUEST] Body re√ßu:', JSON.stringify(requestBody, null, 2));
    
    const { context, scenario, visualType, domain } = requestBody;

    // Validation des param√®tres
    if (!context || !scenario || !visualType || !domain) {
      console.error('‚ùå [VALIDATION] Param√®tres manquants:', { context: !!context, scenario: !!scenario, visualType: !!visualType, domain: !!domain });
      throw new Error('Param√®tres manquants: context, scenario, visualType et domain sont requis');
    }

    // Determine number of images and types based on context complexity
    const shouldGenerateMultiple = (context.length > 200 || scenario.includes('accident') || scenario.includes('contr√¥le') || scenario.includes('infraction'));
    const numberOfImages = shouldGenerateMultiple ? Math.min(3, Math.floor(Math.random() * 2) + 2) : 1;
    
    console.log('üî¢ [MULTI-GEN] G√©n√©ration de', numberOfImages, 'image(s) selon le contexte');

    // Generate contextual prompts based on training content
    const visualPrompts = {
      'press_clipping': `Create a realistic French newspaper clipping about: ${scenario}. Professional newspaper layout with headline, article text, and publication details. Context: ${context}`,
      'official_document': `Generate an official French administrative document related to: ${scenario}. Professional letterhead, official stamps, formal legal language. Context: ${context}`,
      'social_media': `Create a realistic social media post screenshot about: ${scenario}. Include profile picture, post content, engagement metrics. Context: ${context}`,
      'field_photo': `Generate a realistic photograph of the situation: ${scenario}. Professional documentary style, clear details relevant to the case. Context: ${context}`,
      'infraction_scene': `Create a realistic photo of an infraction scene: ${scenario}. Documentary style showing the violation clearly. Context: ${context}`,
      'legal_form': `Generate an official French legal form or report related to: ${scenario}. Professional administrative layout. Context: ${context}`
    };

    // Select visual types based on context
    const getVisualTypes = (primaryType: string, count: number) => {
      const types = [primaryType];
      const alternatives = ['field_photo', 'official_document', 'press_clipping'];
      
      for (let i = 1; i < count; i++) {
        const available = alternatives.filter(t => !types.includes(t));
        if (available.length > 0) {
          types.push(available[Math.floor(Math.random() * available.length)]);
        }
      }
      return types;
    };

    const visualTypes = getVisualTypes(visualType, numberOfImages);
    const images = [];
    
    console.log('üé® [TYPES] Types d\'images √† g√©n√©rer:', visualTypes);

    // Generate images sequentially to avoid rate limits
    for (let i = 0; i < visualTypes.length; i++) {
      const currentType = visualTypes[i];
      const prompt = visualPrompts[currentType] || visualPrompts['field_photo'];
      
      console.log(`üìù [PROMPT-${i+1}] Type: ${currentType}, Prompt:`, prompt.substring(0, 200) + '...');

      // Configuration optimis√©e de la requ√™te OpenAI pour GPT-Image-1
      const requestPayload = {
        model: 'gpt-image-1',
        prompt: prompt,
        n: 1,
        size: '1024x1024', // Format support√© par OpenAI
        output_format: 'webp',
        quality: 'medium', // R√©duit de 'high' pour performance
        output_compression: 70 // Ajoute compression pour r√©duire la taille
      };

      console.log(`üöÄ [OPENAI-REQ-${i+1}] Payload envoy√©:`, JSON.stringify(requestPayload, null, 2));
      console.log(`üåê [OPENAI-REQ-${i+1}] Endpoint: /v1/images/generations`);

      try {
        const response = await fetch('https://api.openai.com/v1/images/generations', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${openAIApiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(requestPayload),
        });

        console.log(`üì° [OPENAI-RESP-${i+1}] Status:`, response.status, response.statusText);
        console.log(`üì° [OPENAI-RESP-${i+1}] Headers:`, Object.fromEntries(response.headers.entries()));

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`‚ùå [OPENAI-ERROR-${i+1}] R√©ponse brute:`, errorText);
          
          // Continue avec l'image suivante en cas d'erreur
          console.warn(`‚ö†Ô∏è [SKIP-${i+1}] Image ${i+1} √©chou√©e, passage √† la suivante`);
          continue;
        }

        const responseText = await response.text();
        console.log(`üìÑ [OPENAI-RESP-${i+1}] R√©ponse brute (100 premiers chars):`, responseText.substring(0, 100));
        
        let data;
        try {
          data = JSON.parse(responseText);
          console.log(`‚úÖ [OPENAI-RESP-${i+1}] JSON pars√© avec succ√®s`);
        } catch (parseError) {
          console.error(`‚ùå [PARSE-ERROR-${i+1}] Impossible de parser la r√©ponse JSON:`, parseError);
          continue;
        }
        
        // Extract image from GPT-Image-1 response
        let imageData;
        
        if (data.data && data.data.length > 0) {
          console.log(`üîç [IMAGE-EXTRACT-${i+1}] Tentative extraction depuis data[0]`);
          imageData = data.data[0].b64_json || data.data[0].url;
          console.log(`üîç [IMAGE-EXTRACT-${i+1}] Type de donn√©es trouv√©es:`, typeof imageData, 'Longueur:', imageData?.length || 0);
        }
        
        if (!imageData) {
          console.error(`‚ùå [IMAGE-EXTRACT-${i+1}] Aucune donn√©e image trouv√©e`);
          continue;
        }

        console.log(`‚úÖ [SUCCESS-${i+1}] Image ${i+1} g√©n√©r√©e avec succ√®s`);
        console.log(`üìè [SUCCESS-${i+1}] Taille de l'image base64:`, imageData.length, 'caract√®res');

        // Ajouter l'image √† la collection
        images.push({
          image: imageData.startsWith('data:') ? imageData : `data:image/webp;base64,${imageData}`,
          visualType: currentType,
          domain,
          prompt: prompt.substring(0, 150) + '...'
        });

        // Petite pause entre les g√©n√©rations pour √©viter le rate limit
        if (i < visualTypes.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 1000));
        }

      } catch (error) {
        console.error(`‚ùå [ERROR-${i+1}] Erreur lors de la g√©n√©ration de l'image ${i+1}:`, error);
        continue;
      }
    }

    // V√©rification qu'au moins une image a √©t√© g√©n√©r√©e
    if (images.length === 0) {
      console.error('‚ùå [FINAL-ERROR] Aucune image n\'a pu √™tre g√©n√©r√©e');
      throw new Error('√âchec de la g√©n√©ration de toutes les images');
    }

    console.log(`üéâ [FINAL-SUCCESS] ${images.length} image(s) g√©n√©r√©e(s) avec succ√®s sur ${numberOfImages} demand√©e(s)`);

    const resultPayload = {
      images: images,
      totalGenerated: images.length,
      requestedCount: numberOfImages,
      visualTypes: visualTypes
    };

    console.log('üì§ [RESPONSE] Payload de retour pr√©par√©:', {
      ...resultPayload,
      images: resultPayload.images.map((img, idx) => ({
        ...img,
        image: img.image.substring(0, 50) + '...(truncated)'
      }))
    });

    return new Response(JSON.stringify(resultPayload), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('Error in generate-training-visuals function:', error);
    return new Response(JSON.stringify({ 
      error: error.message,
      details: 'Failed to generate training visual with GPT-Image-1'
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});